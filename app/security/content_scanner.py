"""File content scanning for security validation.

This module provides pattern-based scanning to detect malicious content
in uploaded G-code files.
"""

import logging
import re
from pathlib import Path

from app.config.settings import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)

# Suspicious patterns that might indicate malicious content
SUSPICIOUS_PATTERNS = {
    "shell_command": [
        r"\$\(.*\)",  # Command substitution $(...)
        r"`.*`",  # Backtick execution
        r";\s*(?:rm|wget|curl|nc|bash|sh|python|perl)\s",  # Chained shell commands
        r"\|\s*(?:bash|sh)\s",  # Piped to shell
    ],
    "path_traversal": [
        r"\.\.[/\\]",  # Directory traversal ../
        r"(?:C|D|E):[/\\]",  # Absolute Windows paths
        r"^/(?:etc|usr|var|bin|home)/",  # Absolute Unix system paths
    ],
    "script_injection": [
        r"<script",  # JavaScript injection
        r"exec\s*\(",  # Python exec
        r"eval\s*\(",  # Eval functions
        r"__import__",  # Python dynamic imports
    ],
    "dangerous_gcode": [
        r"M110\s",  # Reset line numbers (potential confusion)
        r"M503\s",  # Report settings (info leak)
        r"M540\s",  # MAC address (network config)
        r"M997\s",  # Reset/update firmware
    ],
    "encoded_payload": [
        r"base64",  # Base64 encoding
        r"\\x[0-9a-fA-F]{2}",  # Hex encoding
        r"\\u[0-9a-fA-F]{4}",  # Unicode escaping
    ],
}

# Whitelist patterns that are safe even if they match suspicious patterns
WHITELIST_PATTERNS = [
    r";.*\$",  # Comments ending with $ are safe
    r";.*`",  # Comments with backticks are safe
    r";\s*Generated by",  # Slicer identification comments
    r";\s*FLAVOR:",  # G-code flavor comments
]


class FileContentScanner:
    """Scanner for detecting malicious content in uploaded files."""

    def __init__(self):
        """Initialize the file content scanner."""
        self.enabled = settings.FILE_SCANNING_ENABLED
        self.strict_mode = settings.FILE_SCANNING_STRICT_MODE

        # Compile patterns for performance
        self.compiled_patterns = {
            category: [re.compile(pattern, re.IGNORECASE) for pattern in patterns]
            for category, patterns in SUSPICIOUS_PATTERNS.items()
        }
        self.compiled_whitelist = [
            re.compile(pattern, re.IGNORECASE) for pattern in WHITELIST_PATTERNS
        ]

    def scan_file(self, file_path: Path) -> tuple[bool, str | None]:
        """Scan a file for suspicious content.

        Args:
            file_path: Path to the file to scan

        Returns:
            Tuple of (is_safe, reason)
            - is_safe: True if file is safe, False if suspicious
            - reason: Description of why file is suspicious (None if safe)
        """
        if not self.enabled:
            return True, None

        if not file_path.exists():
            return False, "File does not exist"

        try:
            # Read file content (first 1MB is enough for pattern matching)
            max_scan_size = 1024 * 1024  # 1 MB
            with file_path.open("r", encoding="utf-8", errors="ignore") as f:
                content = f.read(max_scan_size)

            # Scan for suspicious patterns
            for category, compiled_patterns in self.compiled_patterns.items():
                for pattern in compiled_patterns:
                    matches = pattern.finditer(content)
                    for match in matches:
                        # Check if match is whitelisted
                        line_start = max(0, match.start() - 100)
                        line_end = min(len(content), match.end() + 100)
                        context = content[line_start:line_end]

                        if self._is_whitelisted(context):
                            continue

                        # Found suspicious content
                        reason = f"Suspicious content detected ({category}): {match.group()[:50]}"
                        logger.warning(
                            f"File content scan detected suspicious pattern: {file_path.name}",
                            extra={
                                "context": {
                                    "filename": file_path.name,
                                    "category": category,
                                    "pattern": pattern.pattern,
                                    "match": match.group()[:100],
                                }
                            },
                        )

                        if self.strict_mode:
                            return False, reason

                        # In non-strict mode, log but continue scanning
                        logger.info(f"Non-strict mode: continuing scan despite {category} match")

            return True, None

        except Exception as e:
            logger.error(
                f"Error scanning file: {e}",
                extra={
                    "context": {
                        "filename": file_path.name,
                        "error": str(e),
                    }
                },
            )
            # On error, fail safe (allow file) unless in strict mode
            if self.strict_mode:
                return False, f"Scan error: {e}"
            return True, None

    def _is_whitelisted(self, context: str) -> bool:
        """Check if a match context is whitelisted.

        Args:
            context: Text context around the match

        Returns:
            True if context matches whitelist pattern
        """
        return any(pattern.search(context) for pattern in self.compiled_whitelist)

    def scan_content(self, content: str) -> tuple[bool, str | None]:
        """Scan content string for suspicious patterns.

        Args:
            content: The content to scan

        Returns:
            Tuple of (is_safe, reason)
        """
        if not self.enabled:
            return True, None

        # Scan for suspicious patterns
        for category, compiled_patterns in self.compiled_patterns.items():
            for pattern in compiled_patterns:
                matches = pattern.finditer(content)
                for match in matches:
                    # Check if match is whitelisted
                    line_start = max(0, match.start() - 100)
                    line_end = min(len(content), match.end() + 100)
                    context = content[line_start:line_end]

                    if self._is_whitelisted(context):
                        continue

                    # Found suspicious content
                    reason = f"Suspicious content detected ({category}): {match.group()[:50]}"
                    logger.warning(
                        "Content scan detected suspicious pattern",
                        extra={
                            "context": {
                                "category": category,
                                "pattern": pattern.pattern,
                                "match": match.group()[:100],
                            }
                        },
                    )

                    if self.strict_mode:
                        return False, reason

        return True, None


# Global scanner instance
scanner = FileContentScanner()
